# llm-vlm_Voxposer_tabletop_implementation
voxposer extracts language conditioned affordances and constraints from llms and grounds them to the perceptual space using VLms, using a python code interface and without additional training to either component, to compose a 3D value maps, which are further used by motion planners to zero-shot synthesize trajectories for everyday manipulation task
